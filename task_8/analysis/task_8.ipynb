{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### task_8.ipynb\n",
    "\n",
    "## Gizem Kilicgedik \tOctober 29, 2023\n",
    "\n",
    "## This is the python code for Task 8 which consists of three sub-tasks.\n",
    "\n",
    "## Setting up the packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import string  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d629e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "inputpath=r'/Users/gizemkilicgedik/Documents/GitHub/AppliedEmpirical/task_8/raw'\n",
    "outputpath=r'/Users/gizemkilicgedik/Documents/GitHub/AppliedEmpirical/task_8/analysis_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0bae74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_to_kilometers(miles):\n",
    "    # Conversion factor for miles to kilometers\n",
    "    conversion_factor = 1.60934\n",
    "    kilometers = miles * conversion_factor\n",
    "    return kilometers\n",
    "\n",
    "def get_miles_from_user():\n",
    "    while True:\n",
    "        try:\n",
    "            miles = float(input(\"Enter the miles per hour: \"))\n",
    "            return miles\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Miles to Kilometers Converter\")\n",
    "    miles = get_miles_from_user()\n",
    "    kilometers = miles_to_kilometers(miles)\n",
    "    print(f\"{miles} miles per hour is approximately {kilometers:.2f} kilometers per hour.\")\n",
    "\n",
    "if __name__ == \"__main\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12eaef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palindrome Detector\n",
      "Enter text to check for palindrome: tottu\n",
      "'tottu' is not a palindrome.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def is_palindrome(text):\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    text = ''.join(char for char in text if char.isalnum()).lower()\n",
    "    \n",
    "    # Check if the cleaned text is equal to its reverse\n",
    "    return text == text[::-1]\n",
    "\n",
    "def get_text_from_user():\n",
    "    text = input(\"Enter text to check for palindrome: \")\n",
    "    return text\n",
    "\n",
    "def main():\n",
    "    print(\"Palindrome Detector\")\n",
    "    text = get_text_from_user()\n",
    "    if is_palindrome(text):\n",
    "        print(f\"'{text}' is a palindrome!\")\n",
    "    else:\n",
    "        print(f\"'{text}' is not a palindrome.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "540f0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_and_process_word(word, stopwords):\n",
    "    word = re.sub(r'[^a-zA-Z]', '', word).lower() \n",
    "    if word not in stopwords:\n",
    "        return word\n",
    "    \n",
    "def count_and_save_word_frequency(directory, congress, stopwords):\n",
    "    word_frequencies = {}\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            file_name = filename.replace('.txt', '')\n",
    "            congress, name, state = filename.split('-')\n",
    "\n",
    "            with open(os.path.join(dirpath, filename), 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                speech = file.read()\n",
    "                words = speech.split()\n",
    "                \n",
    "                for word in words:\n",
    "                    cleaned_word = clean_and_process_word(word, stopwords)\n",
    "                    if cleaned_word:\n",
    "                        key = (congress, name, state, cleaned_word)\n",
    "                        word_frequencies[key] = word_frequencies.get(key, 0) + 1\n",
    "\n",
    "    with open(f'word_frequencies_{congress}.csv', 'w') as output_file:\n",
    "        output_file.write(\"file_name,word,frequency\\n\")\n",
    "        for key, frequency in word_frequencies.items():\n",
    "            output_file.write(f\"{key[0]}-{key[1]}-{key[2]}.txt,{key[3]},{frequency}\\n\")\n",
    "\n",
    "def load_stopwords(stopwords_file):\n",
    "    with open(stopwords_file, 'r') as file:\n",
    "        stopwords = {line.strip() for line in file}\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_105 = \"/Users/gizemkilicgedik/Documents/GitHub/AppliedEmpirical/task_8/raw/105-extracted-date\" \n",
    "    directory_106 = \"/Users/gizemkilicgedik/Documents/GitHub/AppliedEmpirical/task_8/raw/106-extracted-date\" \n",
    "    stopwords_file = \"/Users/gizemkilicgedik/Documents/GitHub/AppliedEmpirical/task_8/raw/droplist.txt\" \n",
    "    stopwords = load_stopwords(stopwords_file)\n",
    "\n",
    "    count_and_save_word_frequency(directory_105, \"105\", stopwords)\n",
    "    count_and_save_word_frequency(directory_106, \"106\", stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce5cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
